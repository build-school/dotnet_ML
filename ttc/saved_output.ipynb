{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with a Pre-Trained Language Model using .Net\n",
    "The purpose of this notebook is to show how to use pre-trained weights from BERT (or another Tensorflow) 'language' model to train a classifier in .Net (specifically F#).\n",
    "\n",
    "The text classification task is more easily accomplished in Python due to the supportive ecosystem available there. The website [Hugging Face](https://huggingface.co/transformers/) contains 1000's of pre-trained language models that can be easily consumed using tooling supplied by Hugging Face. \n",
    "\n",
    "Python however is not the language of choice when it comes to building high-performance applications. To consume language (or other deep learning) models from an application one usually resorts to deploying the model as a service - with attendant cost, security and integration concerns. For a high-performance application, there may be a need to more tightly integrate the model with other application functionality and therefore an embedded model may be required.\n",
    "\n",
    "This notebook shows how a language model maybe re-trained and used directly from .Net, bypassing the need to deploy the model as a service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e644ba41",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>FsBERTTokenizer, 1.0.0</span></li><li><span>FSharp.Data, 6.3.0</span></li><li><span>TfCheckpoint, 1.0.0</span></li><li><span>TorchSharp, 0.101.5</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extensions from `C:\\Users\\Administrator\\.nuget\\packages\\skiasharp\\2.88.6\\interactive-extensions\\dotnet\\SkiaSharp.DotNet.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch devices is cuda\n"
     ]
    }
   ],
   "source": [
    "//#r \"nuget: torchsharp-cpu\" //for cpu\n",
    "//#r \"nuget: libtorch-cuda-11.3-win-x64\"\n",
    "#r \"nuget: torchsharp-cuda-windows\" //for gpu\n",
    "#r \"nuget: TorchSharp\"\n",
    "#r \"nuget: TfCheckpoint\"   \n",
    "#r \"nuget: FsBERTTokenizer\"\n",
    "#r \"nuget: FSharp.Data\"\n",
    "open TfCheckpoint\n",
    "open TorchSharp\n",
    "\n",
    "let device = if torch.cuda_is_available() then torch.CUDA else torch.CPU\n",
    "printfn $\"torch devices is %A{device}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e12e6d",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch devices is cuda\n"
     ]
    }
   ],
   "source": [
    "open TfCheckpoint\n",
    "open TorchSharp\n",
    "\n",
    "let device = if torch.cuda_is_available() then torch.CUDA else torch.CPU\n",
    "printfn $\"torch devices is %A{device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weigths from pre-trained BERT 'checkpoint'\n",
    "Here the pre-trained weights from the 'small' BERT uncased model are used - downloaded from [Tensorflow Hub](https://tfhub.dev/google/small_bert/bert_uncased_L-2_H-128_A-2/2).\n",
    "\n",
    "Note: The weights can also be downloaded from Hugging Face, however they are not easily extractable from languages other than Python. Hugging Face creates its own wrapped packages that require Hugging Face tooling to use.\n",
    "\n",
    "The download includes a folder called 'variables' that contains the pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ffca23d",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"bert/embeddings/LayerNorm/beta\",\n",
      " { Shape = [|128L|]\n",
      "   Tensor =\n",
      "    TdFloat\n",
      "      [|0.1427177936f; 0.1417384148f; 0.1129989177f; 0.008431605063f;\n",
      "        -0.3839171827f; -0.04579306394f; -0.009391464293f; 0.2562615871f;\n",
      "        0.02031775191f; -0.1169935018f; 0.04341379181f; -0.03693608567f;\n",
      "        -0.1498966217f; -0.04671567678f; -0.05263318121f; -0.1550539136f;\n",
      "        0.1118891314f; -0.2280282229f; 0.01878583431f; 0.0003494967241f;\n",
      "        0.1215098947f; -0.2769323587f; -0.2301771045f; -0.593540132f;\n",
      "        -0.01692879945f; -0.005055753049f; 0.09231737256f; 0.01337191183f;\n",
      "        -0.2198150158f; -0.3343744278f; -0.3485637009f; -0.4727560282f;\n",
      "        -0.03425497934f; 0.01004845928f; -0.009842976928f; -0.1552859247f;\n",
      "        -0.1210347489f; 0.09292084724f; 0.1551780701f; -0.2503150105f;\n",
      "        0.01316787116f; -0.06462553144f; -0.4156924486f; 0.1022200063f;\n",
      "        -0.03140406683f; 0.2214509994f; 0.09048749506f; 0.2421075106f;\n",
      "        -0.2365095466f; 0.06668421626f; 0.1963646859f; 0.1197723746f;\n",
      "        -0.08394248784f; 0.2961205542f; 0.2564467788f; 0.0543651022f;\n",
      "        0.1783883423f; -0.2799687386f; -0.145049125f; -0.1192677319f;\n",
      "        -0.07890660316f; -0.1987643242f; -0.3815532327f; 0.2429409772f;\n",
      "        -0.1923356205f; -0.08475973457f; -0.03282091022f; -0.03904989734f;\n",
      "        -0.05057211965f; 0.1082714349f; -0.0855319798f; 0.2224779278f;\n",
      "        -0.1498326063f; -0.3143232167f; -0.07393050939f; -0.02140595764f;\n",
      "        -0.1140864119f; 0.06725683063f; -0.3671147227f; -0.8035869002f;\n",
      "        -0.2137966454f; 0.2168199122f; -0.04170248285f; -0.5436524749f;\n",
      "        0.03476501256f; -0.2010415047f; -0.05343238264f; 0.07493341714f;\n",
      "        -0.07146064937f; 0.1322321892f; -0.09058468789f; -0.05177679658f;\n",
      "        -0.06401548535f; 0.2640584111f; -0.1561880112f; -0.07549760491f;\n",
      "        0.06026218832f; 0.0143991299f; 0.2228940427f; 0.2273250818f; ...|] })\n"
     ]
    }
   ],
   "source": [
    "let bertCheckpointFolder = @\".\\Variables\"\n",
    "let tensors = CheckpointReader.readCheckpoint bertCheckpointFolder |> Seq.toArray\n",
    "//show first tensor\n",
    "printfn \"%A\" tensors.[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above output, the first tensor is named *\"bert/embeddings/LayerNorm/beta\"*. It is a float32 array of shape 1x128. \n",
    "\n",
    "Note the TfCheckpoint package keeps tensors as flat arrays. These can be reshaped when loading into other Tensor libraries e.g. TorchSharp as shown later.\n",
    "\n",
    "### List checkpoint tensors\n",
    "Below are all the tensor names in the pre-trained BERT checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33df6668",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/embeddings/LayerNorm/beta&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/embeddings/LayerNorm/beta</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>1</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/embeddings/LayerNorm/gamma&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/embeddings/LayerNorm/gamma</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>2</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|512L; 128L|]\\n  Name = &quot;bert/embeddings/position_embeddings&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 512, 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/embeddings/position_embeddings</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>3</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|2L; 128L|]\\n  Name = &quot;bert/embeddings/token_type_embeddings&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 2, 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/embeddings/token_type_embeddings</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>4</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|30522L; 128L|]\\n  Name = &quot;bert/embeddings/word_embeddings&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 30522, 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/embeddings/word_embeddings</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>5</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/output/LayerNorm/beta&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/output/LayerNorm/beta</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>6</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/output/LayerNorm/gamma&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/output/LayerNorm/gamma</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>7</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/output/dense/bias&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/output/dense/bias</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>8</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L; 128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/output/dense/kernel&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128, 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/output/dense/kernel</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>9</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/self/key/bias&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/self/key/bias</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>10</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L; 128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/self/key/kernel&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128, 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/self/key/kernel</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>11</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/self/query/bias&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/self/query/bias</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>12</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L; 128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/self/query/kernel&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128, 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/self/query/kernel</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>13</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/self/value/bias&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/self/value/bias</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>14</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L; 128L|]\\n  Name = &quot;bert/encoder/layer_0/attention/self/value/kernel&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128, 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/attention/self/value/kernel</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>15</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|512L|]\\n  Name = &quot;bert/encoder/layer_0/intermediate/dense/bias&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 512 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/intermediate/dense/bias</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>16</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L; 512L|]\\n  Name = &quot;bert/encoder/layer_0/intermediate/dense/kernel&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128, 512 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/intermediate/dense/kernel</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>17</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/output/LayerNorm/beta&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/output/LayerNorm/beta</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>18</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/output/LayerNorm/gamma&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/output/LayerNorm/gamma</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>19</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>{ Dims = [|128L|]\\n  Name = &quot;bert/encoder/layer_0/output/dense/bias&quot; }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Dims</td><td><div class=\"dni-plaintext\"><pre>[ 128 ]</pre></div></td></tr><tr><td>Name</td><td><div class=\"dni-plaintext\"><pre>bert/encoder/layer_0/output/dense/bias</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td colspan=\"2\"><i>(24 more)</i></td></tr></tbody></table><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensors (* |> Array.skip 20 *) |> Array.map (fun (n,st) -> {|Dims=st.Shape; Name=n|})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Small BERT Model\n",
    "The small BERT model used here ('small_bert_bert_uncased_L-2_H-128') requries lower cased text and has hidden layer size of 128. It has two 'transformer' layers. There are many versions of BERT available - from tiny to large. See the [text classification tutorial](https://www.tensorflow.org/text/tutorials/classify_text_with_bert) from Tensforflow for more details.\n",
    "\n",
    "We will re-construct the BERT model using TorchSharp (.Net binding to PyTorch) code and then load the pre-trained weights. The weights will have to be mapped manually. This requires some knowledge of [Tranformers/BERT](https://arxiv.org/abs/1810.04805). However, our task is made easier because TorchSharp (PyTorch) provides a pre-built [TransformerEncoderLayer](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html) which encapulates the basic structure of Transformer-based models.\n",
    "\n",
    "We are required to reconstruct the exact structure of BERT layer-by-layer to ensure the weights are applicable. For re-training we may exclude the final layers and only build the model up to the output of the encoder. For our needs, we wil use the pre-trained weights that start with 'bert/' prefix (see above) and ignore the rest.\n",
    "\n",
    "### Bert Layers\n",
    "The top level layers we will need are:\n",
    "- *Embedding layer*: With sub-layers for word, position & token-type embeddings; layer normalization and dropout. Embedding maps an index to its corresponding learned feature vector.\n",
    "- *Transfomer Encoder layer*: With two sub-layers that apply the core transformer functionality.\n",
    "- *Pooling*: Pools (summarizes) the output sequence into a single value - its encoded representation\n",
    "\n",
    "The rest of the layers will be custom built for text classification (later).\n",
    "\n",
    "### Other Parameters\n",
    "Additional model parameters are required, e.g. vocabulary size, dropout rate, etc. Some of these maybe obtained from Hugging Face from the [BERT model 'card' config file](https://huggingface.co/bert-base-uncased/blob/main/config.json). Here we have defined the required parameters as constants in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04bb6bf",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "//tensor dims - these values should match the relevant dimensions of the corresponding tensors in the checkpoint\n",
    "let HIDDEN      = 128L\n",
    "let VOCAB_SIZE  = 30522L    // see vocab.txt file included in the BERT download\n",
    "let TYPE_SIZE   = 2L         // bert needs 'type' of token\n",
    "let MAX_POS_EMB = 512L\n",
    "\n",
    "//other parameters\n",
    "let EPS_LAYER_NORM      = 1e-12\n",
    "let HIDDEN_DROPOUT_PROB = 0.1\n",
    "let N_HEADS             = 2L\n",
    "let ATTN_DROPOUT_PROB   = 0.1\n",
    "let ENCODER_LAYERS      = 2L\n",
    "let ENCODER_ACTIVATION  = torch.nn.Activations.GELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35abb738",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "//Note: The module and variable names used here match the tensor name 'paths' as delimted by '/' for TF (see above), \n",
    "//for easier matching.\n",
    "type BertEmbedding() as this = \n",
    "    inherit torch.nn.Module(\"embeddings\")\n",
    "    \n",
    "    let word_embeddings         = torch.nn.Embedding(VOCAB_SIZE,HIDDEN,padding_idx=0L)\n",
    "    let position_embeddings     = torch.nn.Embedding(MAX_POS_EMB,HIDDEN)\n",
    "    let token_type_embeddings   = torch.nn.Embedding(TYPE_SIZE,HIDDEN)\n",
    "    let LayerNorm               = torch.nn.LayerNorm([|HIDDEN|],EPS_LAYER_NORM)\n",
    "    let dropout                 = torch.nn.Dropout(HIDDEN_DROPOUT_PROB)\n",
    "\n",
    "    do \n",
    "        this.RegisterComponents()\n",
    "\n",
    "    member this.forward(input_ids:torch.Tensor, token_type_ids:torch.Tensor, position_ids:torch.Tensor) =   \n",
    "    \n",
    "        let embeddings =      \n",
    "            (input_ids       --> word_embeddings)        +\n",
    "            (token_type_ids  --> token_type_embeddings)  +\n",
    "            (position_ids    --> position_embeddings)\n",
    "\n",
    "        embeddings --> LayerNorm --> dropout             // the --> operator works for simple 'forward' invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8adfdcc3",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "type BertPooler() as this = \n",
    "    inherit torch.nn.Module<torch.Tensor,torch.Tensor>(\"pooler\")\n",
    "\n",
    "    let dense = torch.nn.Linear(HIDDEN,HIDDEN)\n",
    "    let activation = torch.nn.Tanh()\n",
    "\n",
    "    let ``:`` = torch.TensorIndex.Colon\n",
    "    let first = torch.TensorIndex.Single(0L)\n",
    "\n",
    "    do\n",
    "        this.RegisterComponents()\n",
    "\n",
    "    override _.forward (hidden_states) =\n",
    "        let first_token_tensor = hidden_states.index(``:``, first) //take first token of the sequence as the pooled value\n",
    "        first_token_tensor --> dense --> activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model \n",
    "Combines the embedding, pooler and transformer encoder layers. (The transformer encoders are available out-of-the-box in PyTroch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50bb310d",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "type BertModel() as this =\n",
    "    inherit torch.nn.Module(\"bert\")\n",
    "\n",
    "    let embeddings = new BertEmbedding()\n",
    "    let pooler = new BertPooler()\n",
    "\n",
    "    let encoderLayer = torch.nn.TransformerEncoderLayer(HIDDEN, N_HEADS, MAX_POS_EMB, ATTN_DROPOUT_PROB, activation=ENCODER_ACTIVATION)\n",
    "    let encoder = torch.nn.TransformerEncoder(encoderLayer, ENCODER_LAYERS)\n",
    "\n",
    "    do\n",
    "        this.RegisterComponents()\n",
    "    \n",
    "    member this.forward(input_ids:torch.Tensor, token_type_ids:torch.Tensor, position_ids:torch.Tensor,?mask:torch.Tensor) =\n",
    "        let src = embeddings.forward(input_ids, token_type_ids, position_ids)\n",
    "        let srcBatchDim2nd = src.permute(1L,0L,2L) //PyTorch transformer requires input as such. See the Transformer docs\n",
    "        let encoded = match mask with None -> encoder.forward(srcBatchDim2nd, null, null) | Some mask -> encoder.forward(srcBatchDim2nd,mask, null)\n",
    "        let encodedBatchFst = encoded.permute(1L,0L,2L)\n",
    "        encodedBatchFst --> pooler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Test BERT Model Instance and Load Pre-Trained TF Weights\n",
    "The main task here is to find the right mapping between the parameters of the BertModel and those form the Tensorflow BERT checkpoint.\n",
    "\n",
    "There are several steps involved - first is create an empty model and list all the parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c90033",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"embeddings.word_embeddings.weight\", [|30522L; 128L|])\n",
      "(\"embeddings.position_embeddings.weight\", [|512L; 128L|])\n",
      "(\"embeddings.token_type_embeddings.weight\", [|2L; 128L|])\n",
      "(\"embeddings.LayerNorm.weight\", [|128L|])\n",
      "(\"embeddings.LayerNorm.bias\", [|128L|])\n",
      "(\"pooler.dense.weight\", [|128L; 128L|])\n",
      "(\"pooler.dense.bias\", [|128L|])\n",
      "(\"encoder.layers.0.self_attn.in_proj_weight\", [|384L; 128L|])\n",
      "(\"encoder.layers.0.self_attn.in_proj_bias\", [|384L|])\n",
      "(\"encoder.layers.0.self_attn.out_proj.weight\", [|128L; 128L|])\n",
      "(\"encoder.layers.0.self_attn.out_proj.bias\", [|128L|])\n",
      "(\"encoder.layers.0.linear1.weight\", [|512L; 128L|])\n",
      "(\"encoder.layers.0.linear1.bias\", [|512L|])\n",
      "(\"encoder.layers.0.linear2.weight\", [|128L; 512L|])\n",
      "(\"encoder.layers.0.linear2.bias\", [|128L|])\n",
      "(\"encoder.layers.0.norm1.weight\", [|128L|])\n",
      "(\"encoder.layers.0.norm1.bias\", [|128L|])\n",
      "(\"encoder.layers.0.norm2.weight\", [|128L|])\n",
      "(\"encoder.layers.0.norm2.bias\", [|128L|])\n",
      "(\"encoder.layers.1.self_attn.in_proj_weight\", [|384L; 128L|])\n",
      "(\"encoder.layers.1.self_attn.in_proj_bias\", [|384L|])\n",
      "(\"encoder.layers.1.self_attn.out_proj.weight\", [|128L; 128L|])\n",
      "(\"encoder.layers.1.self_attn.out_proj.bias\", [|128L|])\n",
      "(\"encoder.layers.1.linear1.weight\", [|512L; 128L|])\n",
      "(\"encoder.layers.1.linear1.bias\", [|512L|])\n",
      "(\"encoder.layers.1.linear2.weight\", [|128L; 512L|])\n",
      "(\"encoder.layers.1.linear2.bias\", [|128L|])\n",
      "(\"encoder.layers.1.norm1.weight\", [|128L|])\n",
      "(\"encoder.layers.1.norm1.bias\", [|128L|])\n",
      "(\"encoder.layers.1.norm2.weight\", [|128L|])\n",
      "(\"encoder.layers.1.norm2.bias\", [|128L|])\n"
     ]
    }
   ],
   "source": [
    "let testBert = new BertModel()\n",
    "//bert.named_modules() \n",
    "testBert.named_parameters() |> Seq.map (fun struct(n,x) -> n,x.shape) |> Seq.iter (printfn \"%A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the names above to the Tensorflow checkpoint names in the beginning, we can find clues as to how the two may be matched. However this is not straigtforward. We need to build some 'infrastructure' to make this work.\n",
    "\n",
    "### Tensor data access helpers\n",
    "First off are some utility functions to get and set data into PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "open System\n",
    "open System.IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6702feba",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "input.fsx (1,1)-(1,1) interactive error internal error: buildGenParam: multiple base types",
     "output_type": "error",
     "traceback": [
      "input.fsx (1,1)-(1,1) interactive error internal error: buildGenParam: multiple base types"
     ]
    }
   ],
   "source": [
    "module Tensor = \n",
    "    //Note: ensure 't matches tensor datatype otherwise ToArray might crash the app (i.e. exception cannot be caught)\n",
    "    let private _getData<'t when 't:>ValueType and 't:struct and 't : (new:unit->'t) and 't:unmanaged > (t:torch.Tensor) =\n",
    "        let s = t.data<'t>()\n",
    "        s.ToArray()\n",
    "\n",
    "    let getData<'t when 't:>ValueType and 't:struct and 't : (new:unit->'t) and 't:unmanaged>  (t:torch.Tensor) =\n",
    "        if t.device_type <> DeviceType.CPU then \n",
    "            //use t1 = t.clone()\n",
    "            use t2 = t.cpu()\n",
    "            _getData<'t> t2\n",
    "        else \n",
    "            _getData<'t> t\n",
    "  \n",
    "    let setData<'t when 't:>ValueType and 't:struct and 't : (new:unit->'t) and 't:unmanaged> (t:torch.Tensor) (data:'t[]) =\n",
    "        if t.device_type = DeviceType.CPU |> not then failwith \"tensor has to be on cpu for setData\"        \n",
    "        let s = t.data<'t>()\n",
    "        s.CopyFrom(data,0,0L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name map\n",
    "The *nameMap* is a 3-tuple list: \n",
    "1. BertModel parameter name; \n",
    "2. List of TF tensor names that should be mapped to the parameter\n",
    "3. Post processing indicator. \n",
    "    \n",
    "In PyTorch, the encoder layer combines the query/key/value weights into a single parameter; these are separate in Tensorflow and therefore a list is requrired to map correctly.\n",
    "\n",
    "The post processing indicator (type **PostProc**) specifies the post processing required for each map entry.\n",
    "\n",
    "The *nameMap* list names contain wildcards ('#') which will be replaced by a number representing the encoder layer. BERT model versions can have different number of transformer layers. The model here has 2 layers but larger BERT models can have upto 12 layers. The wildcard-based mapping scheme is apt to handle an arbitrary number of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1ee10",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "type PostProc = V | H | T | N\n",
    "\n",
    "let postProc (ts:torch.Tensor list) = function\n",
    "    | V -> torch.vstack(ResizeArray ts)\n",
    "    | H -> torch.hstack(ResizeArray ts)\n",
    "    | T -> ts.Head.T                  //Linear layer weights need to be transformed. See https://github.com/pytorch/pytorch/issues/2159\n",
    "    | N -> ts.Head\n",
    "\n",
    "let nameMap =\n",
    "    [\n",
    "        \"encoder.layers.#.self_attn.in_proj_weight\",[\"encoder/layer_#/attention/self/query/kernel\"; \n",
    "                                                     \"encoder/layer_#/attention/self/key/kernel\";    \n",
    "                                                     \"encoder/layer_#/attention/self/value/kernel\"],        V\n",
    "\n",
    "        \"encoder.layers.#.self_attn.in_proj_bias\",  [\"encoder/layer_#/attention/self/query/bias\";\n",
    "                                                     \"encoder/layer_#/attention/self/key/bias\"; \n",
    "                                                     \"encoder/layer_#/attention/self/value/bias\"],          H\n",
    "\n",
    "        \"encoder.layers.#.self_attn.out_proj.weight\", [\"encoder/layer_#/attention/output/dense/kernel\"],    N\n",
    "        \"encoder.layers.#.self_attn.out_proj.bias\",   [\"encoder/layer_#/attention/output/dense/bias\"],      N\n",
    "\n",
    "\n",
    "        \"encoder.layers.#.linear1.weight\",          [\"encoder/layer_#/intermediate/dense/kernel\"],          T\n",
    "        \"encoder.layers.#.linear1.bias\",            [\"encoder/layer_#/intermediate/dense/bias\"],            N\n",
    "\n",
    "        \"encoder.layers.#.linear2.weight\",          [\"encoder/layer_#/output/dense/kernel\"],                T\n",
    "        \"encoder.layers.#.linear2.bias\",            [\"encoder/layer_#/output/dense/bias\"],                  N\n",
    "\n",
    "        \"encoder.layers.#.norm1.weight\",            [\"encoder/layer_#/attention/output/LayerNorm/gamma\"],   N\n",
    "        \"encoder.layers.#.norm1.bias\",              [\"encoder/layer_#/attention/output/LayerNorm/beta\"],    N\n",
    "\n",
    "        \"encoder.layers.#.norm2.weight\",            [\"encoder/layer_#/output/LayerNorm/gamma\"],             N\n",
    "        \"encoder.layers.#.norm2.bias\",              [\"encoder/layer_#/output/LayerNorm/beta\"],              N\n",
    "\n",
    "        \"embeddings.word_embeddings.weight\"         , [\"embeddings/word_embeddings\"]           , N\n",
    "        \"embeddings.position_embeddings.weight\"     , [\"embeddings/position_embeddings\"]       , N\n",
    "        \"embeddings.token_type_embeddings.weight\"   , [\"embeddings/token_type_embeddings\"]     , N\n",
    "        \"embeddings.LayerNorm.weight\"               , [\"embeddings/LayerNorm/gamma\"]           , N\n",
    "        \"embeddings.LayerNorm.bias\"                 , [\"embeddings/LayerNorm/beta\"]            , N\n",
    "        \"pooler.dense.weight\"                       , [\"pooler/dense/kernel\"]                  , T\n",
    "        \"pooler.dense.bias\"                         , [\"pooler/dense/bias\"]                    , N\n",
    "    ]\n",
    "\n",
    "let PREFIX = \"bert\"\n",
    "let addPrefix (s:string) = $\"{PREFIX}/{s}\"\n",
    "let sub n (s:string) = s.Replace(\"#\",string n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name map helpers\n",
    "Functions to set the parameter values of a PyTorch module from a TF checkpoint and a 'nameMap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6085d1e",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "//create a PyTorch tensor from TF checkpoint tensor data\n",
    "let toFloat32Tensor (shpdTnsr:CheckpointReader.ShapedTensor) = \n",
    "    match shpdTnsr.Tensor with\n",
    "    | CheckpointReader.TensorData.TdFloat ds -> torch.tensor(ds, dimensions=shpdTnsr.Shape)\n",
    "    | _                                      -> failwith \"TdFloat expected\"\n",
    "\n",
    "//set the value of a single parameter\n",
    "let performMap (tfMap:Map<string,_>) (ptMap:Map<string,Modules.Parameter>) (torchName,tfNames,postProcType) = \n",
    "    let torchParm = ptMap.[torchName]\n",
    "    let fromTfWts = tfNames |> List.map (fun n -> tfMap.[n] |> toFloat32Tensor) \n",
    "    let parmTensor = postProc fromTfWts postProcType\n",
    "    if torchParm.shape <> parmTensor.shape then failwithf $\"Mismatched weights for parameter {torchName}; parm shape: %A{torchParm.shape} vs tensor shape: %A{parmTensor.shape}\"\n",
    "    Tensor.setData<float32> torchParm (Tensor.getData<float32>(parmTensor))\n",
    "\n",
    "//set the parameter weights of a PyTorch model given checkpoint and nameMap\n",
    "let loadWeights (model:torch.nn.Module) checkpoint encoderLayers nameMap =\n",
    "    let tfMap = checkpoint |> Map.ofSeq\n",
    "    let ptMap = model.named_parameters() |> Seq.map (fun struct(n,m) -> n,m) |> Map.ofSeq\n",
    "\n",
    "    //process encoder layers\n",
    "    for l in 0 .. encoderLayers - 1 do\n",
    "        nameMap\n",
    "        |> List.filter (fun (p:string,_,_) -> p.Contains(\"#\")) \n",
    "        |> List.map (fun (p,tns,postProc) -> sub l p, tns |> List.map (addPrefix >> (sub l)), postProc)\n",
    "        |> List.iter (performMap tfMap ptMap)\n",
    "\n",
    "    nameMap\n",
    "    |> List.filter (fun (p,_,_) -> p.Contains(\"#\") |> not)\n",
    "    |> List.map (fun (name,tns,postProcType) -> name, tns |> List.map addPrefix, postProcType)\n",
    "    |> List.iter (performMap tfMap ptMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights into test model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982f917",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "loadWeights testBert tensors (int ENCODER_LAYERS) nameMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check\n",
    "Do a quick check - print the value of one of the model parameters and compare that to the equivalent one from TF to see if the values look right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f6dc5",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "testBert.get_parameter(\"encoder.layers.0.self_attn.in_proj_weight\") |> Tensor.getData<float32>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d8bf7",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "tensors |> Seq.find (fun (n,_) -> n = \"bert/encoder/layer_0/attention/self/query/kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "The training dataset is the [Yelp review dataset](https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz). Assume this data is saved to a local folder as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da0a8f",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "let foldr = @\".\\yelp_review_polarity_csv\"\n",
    "let testCsv = Path.Combine(foldr,\"test.csv\")\n",
    "let trainCsv = Path.Combine(foldr,\"train.csv\")\n",
    "if File.Exists testCsv |> not then failwith $\"File not found; path = {testCsv}\"\n",
    "printfn \"%A\" trainCsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a33c04",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "open FSharp.Data\n",
    "type YelpCsv = FSharp.Data.CsvProvider< Sample=\"a,b\", HasHeaders=false, Schema=\"Label,Text\">\n",
    "type [<CLIMutable>] YelpReview = {Label:int; Text:string}\n",
    "//need to make labels 0-based so subtract 1\n",
    "let testSet = YelpCsv.Load(testCsv).Rows |> Seq.map (fun r-> {Label=int r.Label - 1; Text=r.Text}) |> Seq.toArray \n",
    "let trainSet = YelpCsv.Load(trainCsv).Rows |> Seq.map (fun r->{Label=int r.Label - 1; Text=r.Text}) |> Seq.toArray\n",
    "testSet.Display() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the number of label classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cdb77",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "let classes = trainSet |> Seq.map (fun x->x.Label) |> set\n",
    "classes.Display()\n",
    "let TGT_LEN = classes.Count |> int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch processing\n",
    "Helpers for serving minibatches of tensors for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33655d",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "let BATCH_SIZE = 128\n",
    "let trainBatches = trainSet |> Seq.chunkBySize BATCH_SIZE\n",
    "let testBatches  = testSet  |> Seq.chunkBySize BATCH_SIZE\n",
    "open BERTTokenizer\n",
    "let vocabFile = @\".\\vocab.txt\"\n",
    "let vocab = Vocabulary.loadFromFile vocabFile\n",
    "\n",
    "let position_ids = torch.arange(MAX_POS_EMB).expand(int64 BATCH_SIZE,-1L).``to``(device)\n",
    "\n",
    "//convert a batch to input and output (X, Y) tensors\n",
    "let toXY (batch:YelpReview[]) = \n",
    "    let xs = batch |> Array.map (fun x-> Featurizer.toFeatures vocab true (int MAX_POS_EMB) x.Text \"\")\n",
    "    let d_tkns      = xs |> Seq.collect (fun f -> f.InputIds )  |> Seq.toArray\n",
    "    let d_tkn_typs  = xs |> Seq.collect (fun f -> f.SegmentIds) |> Seq.toArray\n",
    "    let tokenIds = torch.tensor(d_tkns,     dtype=torch.int).view(-1L,MAX_POS_EMB)        \n",
    "    let sepIds   = torch.tensor(d_tkn_typs, dtype=torch.int).view(-1L,MAX_POS_EMB)\n",
    "    let Y = torch.tensor(batch |> Array.map (fun x->x.Label), dtype=torch.int64).view(-1L)\n",
    "    (tokenIds,sepIds),Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "trainBatches |> Seq.item 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model check\n",
    "Evaluate bert instance with just the first batch of the training data to ensure its can produce the expected output.\n",
    "The expected output is a tensor with the shape BATCH_SIZE x HIDDEN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39b89e",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "testBert.eval()\n",
    "let (_tkns,_seps),_ = trainBatches |> Seq.head |> toXY\n",
    "//_tkns.shape\n",
    "//_tkns |> Tensor.getData<int64>\n",
    "let _testOut = testBert.forward(_tkns,_seps,position_ids.cpu()) //test is on cpu\n",
    "_testOut.shape.Display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend for classification\n",
    "Here the PyTorch multi-class classification method is used. The number of classes is only two for this data but the multi-class method is more general and can be easily extended to more than two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc0bbb",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "type BertClassification() as this = \n",
    "    inherit torch.nn.Module(\"BertClassification\")\n",
    "\n",
    "    let bert = new BertModel()\n",
    "    let proj = torch.nn.Linear(HIDDEN,TGT_LEN)\n",
    "\n",
    "    do\n",
    "        this.RegisterComponents()\n",
    "        this.LoadBertPretrained()\n",
    "\n",
    "    member _.LoadBertPretrained() =\n",
    "        loadWeights bert tensors (int ENCODER_LAYERS) nameMap\n",
    "    \n",
    "    member _.forward(tknIds,sepIds,pstnIds) =\n",
    "        use encoded = bert.forward(tknIds,sepIds,pstnIds)\n",
    "        encoded --> proj "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b481edf",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "let _model = new BertClassification()\n",
    "_model.``to``(device)\n",
    "let _loss = torch.nn.CrossEntropyLoss()\n",
    "let mutable EPOCHS = 1\n",
    "let mutable verbose = true\n",
    "let gradCap = 0.1f\n",
    "let gradMin,gradMax = (-gradCap).ToScalar(),  gradCap.ToScalar()\n",
    "let opt = torch.optim.Adam(_model.parameters (), 0.001, amsgrad=true)       \n",
    "\n",
    "let class_accuracy (y:torch.Tensor) (y':torch.Tensor) =\n",
    "    use i = y'.argmax(1L)\n",
    "    let i_t = Tensor.getData<int64>(i)\n",
    "    let m_t = Tensor.getData<int64>(y)\n",
    "    Seq.zip i_t m_t \n",
    "    |> Seq.map (fun (a,b) -> if a = b then 1.0 else 0.0) \n",
    "    |> Seq.average\n",
    "\n",
    "//adjustment for end of data when full batch may not be available\n",
    "let adjPositions currBatchSize = if int currBatchSize = BATCH_SIZE then position_ids else torch.arange(MAX_POS_EMB).expand(currBatchSize,-1L).``to``(device)\n",
    "\n",
    "let dispose ls = ls |> List.iter (fun (x:IDisposable) -> x.Dispose())\n",
    "\n",
    "//run a batch through the model; return true output, predicted output and loss tensors\n",
    "let processBatch ((tkns:torch.Tensor,typs:torch.Tensor), y:torch.Tensor) =\n",
    "    use tkns_d = tkns.``to``(device)\n",
    "    use typs_d = typs.``to``(device)\n",
    "    let y_d    = y.``to``(device)            \n",
    "    let pstns  = adjPositions tkns.shape.[0]\n",
    "    if device <> torch.CPU then //these were copied so ok to dispose old tensors\n",
    "        dispose [tkns; typs; y]\n",
    "    let y' = _model.forward(tkns_d,typs_d,pstns)\n",
    "    let loss = _loss.forward(y', y_d)   \n",
    "    y_d,y',loss\n",
    "\n",
    "//evaluate on test set; return cross-entropy loss and classification accuracy\n",
    "let evaluate e =\n",
    "    _model.eval()\n",
    "    let lss =\n",
    "        testBatches \n",
    "        |> Seq.map toXY\n",
    "        |> Seq.map (fun batch ->\n",
    "            let y,y',loss = processBatch batch\n",
    "            let ls = loss.ToDouble()\n",
    "            let acc = class_accuracy y y'            \n",
    "            dispose [y;y';loss]\n",
    "            GC.Collect()\n",
    "            ls,acc)\n",
    "        |> Seq.toArray\n",
    "    let ls  = lss |> Seq.averageBy fst\n",
    "    let acc = lss |> Seq.averageBy snd\n",
    "    ls,acc\n",
    "\n",
    "let mutable e = 0\n",
    "let train () =\n",
    "    \n",
    "    while e < EPOCHS do\n",
    "        e <- e + 1\n",
    "        _model.train()\n",
    "        let losses = \n",
    "            trainBatches \n",
    "            |> Seq.map toXY\n",
    "            |> Seq.mapi (fun i batch ->                 \n",
    "                opt.zero_grad ()   \n",
    "                let y,y',loss = processBatch batch\n",
    "                let ls = loss.ToDouble()  \n",
    "                loss.backward()\n",
    "                _model.parameters() |> Seq.iter (fun t -> t.grad().clip(gradMin,gradMax) |> ignore)                            \n",
    "                use  t_opt = opt.step ()\n",
    "                if verbose && i % 100 = 0 then\n",
    "                    let acc = class_accuracy y y'\n",
    "                    printfn $\"Epoch: {e}, minibatch: {i}, ce: {ls}, accuracy: {acc}\"                            \n",
    "                dispose [y;y';loss]\n",
    "                GC.Collect()\n",
    "                ls)\n",
    "            |> Seq.toArray\n",
    "\n",
    "        let evalCE,evalAcc = evaluate e\n",
    "        printfn $\"Epoch {e} train: {Seq.average losses}; eval acc: {evalAcc}\"\n",
    "\n",
    "    printfn \"Done train\"\n",
    "\n",
    "let runner () = async { do train () } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a07ae",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "runner() |> Async.RunSynchronously\n",
    "(*\n",
    "\n",
    "sample output:\n",
    "...\n",
    "Epoch: 2, minibatch: 4200, ce: 0.14490307867527008, accuracy: 0.9375\n",
    "Epoch: 2, minibatch: 4300, ce: 0.04636668041348457, accuracy: 0.984375\n",
    "Epoch 2 train: 0.15354100534277304; eval acc: 0.9376728595478595\n",
    "*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://onnxruntime.ai/docs/tutorials/csharp/bert-nlp-csharp-console-app.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     },
     {
      "aliases": [
       "frontend"
      ],
      "name": "vscode"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
